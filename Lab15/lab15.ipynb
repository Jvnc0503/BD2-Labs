{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f248124a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab15\n",
    "\n",
    "## P1. (7 pts) Medir la temperatura y la humedad:\n",
    "### Consultas requeridas\n",
    "1. Obtener todas las mediciones de humedad del sensor `SENS001` del último día. La consulta debe incluir el tiempo restante de vida (TTL) de cada registro.\n",
    "\n",
    "2. Detectar valores anómalos fuera del rango permitido en la última hora. Implementar una consulta que identifique mediciones de temperatura o humedad fuera del rango normal. La consulta debe permitir filtrar por sensor específico.\n",
    "\n",
    "3. Verificar el tiempo restante de vida de los datos usando la función TTL. Implementar una consulta que muestre el TTL en diferentes unidades (segundos, horas, días). Crear una consulta para identificar datos que están próximos a expirar (ej: en las próximas 24 horas).\n",
    "\n",
    "### Estructura de tablas propuestas\n",
    "La tabla `sensor_readings` tendrá un propósito general que permite filtrar por tipo de medicion, sensor y día. Esta tabla se usará para la consulta 1.\n",
    "\n",
    "La tabla `sensor_anomalies` será destinada a optimizar la consulta 2, esta nos permite filtrar por hora ya que se incluye este dato en el partition key, además de tener clustering por el valor de la medición lo que facilita hallar los valores anómalos.\n",
    "\n",
    "La tabla `sensor_by_date` fue pensada para usarse con la consulta 3, porque particiona solo por la fecha y con esto poder filtrar los datos con más de 6 días de antigüedad.\n",
    "\n",
    "Se respeta el tiempo de vida de los datos de 7 días de acuerdo a lo solicitado, y se considera adicionalmente un tiempo de vida de solo 2 horas para el seguimiento de datos anómalos ya que se espera que siempre se consulten los insertados en la hora pasada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811eb3c",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "create table if not exists sensor_readings\n",
    "(\n",
    "    measurement_type text,\n",
    "    sensor_id        text,\n",
    "    date             text,\n",
    "    event_time       timestamp,\n",
    "    measurement      double,\n",
    "    primary key ( (measurement_type, sensor_id, date), event_time )\n",
    ") with clustering order by (event_time desc) and\n",
    "        default_time_to_live = 604800; -- 7 days\n",
    "\n",
    "create table if not exists sensor_anomalies\n",
    "(\n",
    "    measurement_type text,\n",
    "    sensor_id        text,\n",
    "    hour             text,\n",
    "    event_time       timestamp,\n",
    "    measurement      double,\n",
    "    primary key ( (measurement_type, sensor_id, hour), measurement, event_time)\n",
    ") with clustering order by (measurement asc, event_time desc) and\n",
    "        default_time_to_live = 7200; -- 2 hour\n",
    "\n",
    "create table if not exists sensor_by_date\n",
    "(\n",
    "    measurement_type text,\n",
    "    sensor_id        text,\n",
    "    date             text,\n",
    "    event_time       timestamp,\n",
    "    measurement      double,\n",
    "    primary key ( date, event_time )\n",
    ") with clustering order by (event_time asc) and\n",
    "        default_time_to_live = 604800; -- 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e96cc4",
   "metadata": {},
   "source": [
    "### Configuración del entorno de trabajo\n",
    "\n",
    "Instalación de driver de cassandra para python, se requiere haber configurado un entorno local de conda previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f58fbb15",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.1\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - anaconda\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - libev\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/anaconda\n",
      "  - defaults\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - msys2\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.1\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.1\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (3.29.2)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.2.1)\n",
      "Requirement already satisfied: six in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda update -n base -c defaults conda\n",
    "%conda install -c anaconda libev\n",
    "%conda install -c msys2 m2-make\n",
    "%conda install -c conda-forge pkg-config\n",
    "%pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b15792",
   "metadata": {},
   "source": [
    "### Generación de datos y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserción de datos de prueba completada.\n",
      "Total de registros insertados: 100810\n",
      "\n",
      "Query 1:\n",
      "Lecturas de temperatura para el sensor SENS001 del día de ayer 2025-07-07:\n",
      "1440 resultados encontrados en 0.0445 segundos\n",
      "  - 2025-07-07 23:59:23: 29.201208291475858 (TTL: 604789 segundos)\n",
      "  - 2025-07-07 23:58:23: 26.325772840598976 (TTL: 604789 segundos)\n",
      "  - 2025-07-07 23:57:23: 16.36373289016412 (TTL: 604789 segundos)\n",
      "  - 2025-07-07 23:56:23: 15.755248981596546 (TTL: 604789 segundos)\n",
      "  - 2025-07-07 23:55:23: 29.982972045719457 (TTL: 604789 segundos)\n",
      "\n",
      "Query 2:\n",
      "Anomalías de humedad para el sensor SENS002 de la hora pasada 2025-07-08T15:\n",
      "20 resultados encontrados en 0.0318 segundos\n",
      "  - 2025-07-08 15:59:23: 26.105229674183267\n",
      "  - 2025-07-08 15:57:23: 84.11479523132168\n",
      "  - 2025-07-08 15:52:23: 29.90490526548601\n",
      "  - 2025-07-08 15:50:23: 29.105740757183067\n",
      "  - 2025-07-08 15:49:23: 26.49023812956321\n",
      "\n",
      "Query 3:\n",
      "Datos de más de 6 días de antigüedad (2025-07-02):\n",
      "1440 resultados encontrados en 0.0457 segundos\n",
      "  - temperatura del sensor SENS005 del día 2025-07-02 (TTL: 604799 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - temperatura del sensor SENS005 del día 2025-07-02 (TTL: 604799 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - temperatura del sensor SENS005 del día 2025-07-02 (TTL: 604799 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - temperatura del sensor SENS005 del día 2025-07-02 (TTL: 604799 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - temperatura del sensor SENS005 del día 2025-07-02 (TTL: 604799 segundos, 10079 minutos, 167 horas, 6 días)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement, BatchType\n",
    "\n",
    "# Parametros de simulación\n",
    "N_SENSORS = 5\n",
    "SAMPLING_RATE = 60 # 1 minuto en segundos\n",
    "SAMPLING_TIME = 604800  # 7 días en segundos\n",
    "ID_PREFIX = 'SENS'\n",
    "MESUREMENTS_TYPES = ('temperatura', 'humedad')\n",
    "NORMAL_RANGE = {'temperatura': (15, 35),\n",
    "                'humedad': (30, 80)}\n",
    "\n",
    "# Precomputar rango extendido de valores para simulación de anomalías\n",
    "EXTENDED_RANGE = {\n",
    "    type: (low - (high - low) * 0.2,\n",
    "        high + (high - low) * 0.2\n",
    "    )\n",
    "    for type, (low, high) in NORMAL_RANGE.items()\n",
    "}\n",
    "\n",
    "# Conexión a Cassandra en Docker\n",
    "cluster = Cluster(\n",
    "  ['localhost'], port=9042,\n",
    "  protocol_version=4,\n",
    "  connect_timeout=5,\n",
    "  idle_heartbeat_interval=30,\n",
    "  control_connection_timeout=10\n",
    ")\n",
    "cassandra = cluster.connect('my_keyspace')\n",
    "\n",
    "def create_tables() -> None:\n",
    "    # Crear tabla para lecturas de sensores\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists sensor_readings\n",
    "        (\n",
    "            measurement_type text,\n",
    "            sensor_id        text,\n",
    "            date             text,\n",
    "            event_time       timestamp,\n",
    "            measurement      double,\n",
    "            primary key ( (measurement_type, sensor_id, date), event_time )\n",
    "        ) with clustering order by (event_time desc) and\n",
    "                default_time_to_live = 604800\n",
    "    \"\"\")\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists sensor_anomalies\n",
    "        (\n",
    "            measurement_type text,\n",
    "            sensor_id        text,\n",
    "            hour             text,\n",
    "            event_time       timestamp,\n",
    "            measurement      double,\n",
    "            primary key ( (measurement_type, sensor_id, hour), measurement, event_time)\n",
    "        ) with clustering order by (measurement asc, event_time desc) and\n",
    "                default_time_to_live = 7200\n",
    "    \"\"\")\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists sensor_by_date\n",
    "        (\n",
    "            measurement_type text,\n",
    "            sensor_id        text,\n",
    "            date             text,\n",
    "            event_time       timestamp,\n",
    "            measurement      double,\n",
    "            primary key ( date, event_time )\n",
    "        ) with clustering order by (event_time asc) and\n",
    "                default_time_to_live = 604800;\n",
    "    \"\"\")\n",
    "\n",
    "def drop_tables() -> None:\n",
    "    # Eliminar tablas si existen\n",
    "    cassandra.execute(\"drop table if exists sensor_readings\")\n",
    "    cassandra.execute(\"drop table if exists sensor_anomalies\")\n",
    "    cassandra.execute(\"drop table if exists sensor_by_date\")\n",
    "    \n",
    "def generate_sensor_data() -> None:\n",
    "    # Generar indetificadores únicos para cada sensor\n",
    "    ids: list[str] = [f\"{ID_PREFIX}{str(i).zfill(3)}\" for i in range(1, N_SENSORS + 1)]\n",
    "\n",
    "    # Preparar queries\n",
    "    insert_reading = cassandra.prepare(\"\"\"\n",
    "        INSERT INTO sensor_readings (measurement_type, sensor_id, date, event_time, measurement)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    insert_anomaly = cassandra.prepare(\"\"\"\n",
    "        INSERT INTO sensor_anomalies (measurement_type, sensor_id, hour, event_time, measurement)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    insert_by_date = cassandra.prepare(\"\"\"\n",
    "        INSERT INTO sensor_by_date (measurement_type, sensor_id, date, event_time, measurement)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "\n",
    "    # Definir el tiempo de inicio y fin para la generación de datos\n",
    "    start_time: datetime = datetime.now() - timedelta(seconds=SAMPLING_TIME)\n",
    "    end_time: datetime = datetime.now()\n",
    "    current_time: datetime = end_time   # Insertar en orden descendente\n",
    "\n",
    "    # Usar BatchStatement para agrupar inserciones\n",
    "    batch = BatchStatement(batch_type=BatchType.UNLOGGED)\n",
    "\n",
    "    # Lista para almacenar las futuras ejecuciones asíncronas\n",
    "    futures = []\n",
    "\n",
    "    # Limite de inflight para evitar sobrecargar Cassandra\n",
    "    max_inflight = 16\n",
    "\n",
    "    while current_time >= start_time:\n",
    "        date = current_time.strftime('%Y-%m-%d')\n",
    "        hour = current_time.strftime('%Y-%m-%dT%H')\n",
    "\n",
    "        for id in ids:\n",
    "            for type in MESUREMENTS_TYPES:\n",
    "                ext_low, ext_high = EXTENDED_RANGE[type]\n",
    "                measurement = random.uniform(ext_low, ext_high)\n",
    "\n",
    "                batch.add(insert_reading, (type, id, date, current_time, measurement))\n",
    "                batch.add(insert_anomaly, (type, id, hour, current_time, measurement))\n",
    "                batch.add(insert_by_date, (type, id, date, current_time, measurement))\n",
    "\n",
    "        # Ejecutar el batch de forma asíncrona\n",
    "        futures.append(cassandra.execute_async(batch))\n",
    "        batch.clear()  # Limpiar el batch para la siguiente iteración\n",
    "\n",
    "        # Si el batch alcanza el límite de inflight, esperar a que se completen\n",
    "        if len(futures) >= max_inflight:\n",
    "            for f in futures:\n",
    "                f.result()\n",
    "            futures.clear()\n",
    "\n",
    "        # Retroceder el tiempo para la siguiente iteración\n",
    "        current_time -= timedelta(seconds=SAMPLING_RATE)\n",
    "    \n",
    "    # Esperar batchs restantes\n",
    "    for f in futures:\n",
    "        f.result()\n",
    "\n",
    "    result = cassandra.execute(\"select count(*) from sensor_readings\")\n",
    "    count = list(result)[0][0]\n",
    "    print(\"Inserción de datos de prueba completada.\\nTotal de registros insertados:\", count)\n",
    "\n",
    "def query_1(type: str, id: str) -> None:\n",
    "    print(\"\\nQuery 1:\")\n",
    "    # Calcular el bucket del día anterior\n",
    "    target_date: str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    # Ejecutar consulta y medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "    rows = cassandra.execute(\"\"\"\n",
    "        select event_time, measurement, ttl(measurement) as ttl\n",
    "        from sensor_readings\n",
    "        where measurement_type = %s\n",
    "            and sensor_id = %s\n",
    "            and date = %s\n",
    "    \"\"\", (type, id, target_date))\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    rows: list = list(rows)  # Convertir a lista para poder usar len() y slicing\n",
    "    print(f\"Lecturas de {type} para el sensor {id} del día de ayer {target_date}:\")\n",
    "    print(f\"{len(rows)} resultados encontrados en {query_time:.4f} segundos\")\n",
    "    for row in rows[:5]:  # Limitar a las primeras 5 lecturas\n",
    "        event_time = row.event_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        measurement = row.measurement\n",
    "        ttl_seconds = row.ttl\n",
    "        print(f\"  - {event_time}: {measurement} (TTL: {ttl_seconds} segundos)\")\n",
    "\n",
    "def query_2(type: str, id: str) -> None:\n",
    "    print(\"\\nQuery 2:\")\n",
    "    # Calcular el bucket de la hora anterior\n",
    "    target_hour: str = (datetime.now() - timedelta(hours=1)).strftime('%Y-%m-%dT%H')\n",
    "    # Obtener el rango normal para el tipo de medición\n",
    "    low, high = NORMAL_RANGE[type]\n",
    "    # Ejecutar consulta y medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "    rows_low = cassandra.execute(\"\"\"\n",
    "        select event_time, measurement\n",
    "        from sensor_anomalies\n",
    "        where measurement_type = %s\n",
    "            and sensor_id = %s\n",
    "            and hour = %s\n",
    "            and measurement < %s\n",
    "    \"\"\", (type, id, target_hour, low))\n",
    "\n",
    "    rows_high = cassandra.execute(\"\"\"\n",
    "        select event_time, measurement\n",
    "        from sensor_anomalies\n",
    "        where measurement_type = %s\n",
    "            and sensor_id = %s\n",
    "            and hour = %s\n",
    "            and measurement > %s\n",
    "    \"\"\", (type, id, target_hour, high))\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    rows: list = list(rows_low) + list(rows_high)\n",
    "    rows.sort(key=lambda row: row.event_time, reverse=True)\n",
    "    print(f\"Anomalías de {type} para el sensor {id} de la hora pasada {target_hour}:\")\n",
    "    print(f\"{len(rows)} resultados encontrados en {query_time:.4f} segundos\")\n",
    "    for row in rows[:5]:  # Limitar a las primeras 5 anomalías\n",
    "        event_time = row.event_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        measurement = row.measurement\n",
    "        print(f\"  - {event_time}: {measurement}\")\n",
    "\n",
    "def query_3() -> None:\n",
    "    print(\"\\nQuery 3:\")\n",
    "    # Calcular el bucket de la fecha de hace 6 días\n",
    "    target_date: str = (datetime.now() - timedelta(days=6)).strftime('%Y-%m-%d')\n",
    "    # Ejecutar consulta y medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "    rows = cassandra.execute(\"\"\"\n",
    "        select measurement_type, sensor_id, date, event_time, ttl(measurement) as ttl\n",
    "        from sensor_by_date\n",
    "        where date = %s\n",
    "    \"\"\", (target_date,))\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    rows: list = list(rows)  # Convertir a lista para poder usar len() y slicing\n",
    "    print(f\"Datos de más de 6 días de antigüedad ({target_date}):\")\n",
    "    print(f\"{len(rows)} resultados encontrados en {query_time:.4f} segundos\")\n",
    "    for row in rows[:5]:  # Limitar a las primeras 5 lecturas\n",
    "        measurement_type = row.measurement_type\n",
    "        sensor_id = row.sensor_id\n",
    "        date = row.date\n",
    "        ttl_seconds = row.ttl\n",
    "        ttl_minutes = ttl_seconds // 60\n",
    "        ttl_hours = ttl_minutes // 60\n",
    "        ttl_days = ttl_hours // 24\n",
    "        print(f\"  - {measurement_type} del sensor {sensor_id} del día {date} (TTL: {ttl_seconds} segundos, {ttl_minutes} minutos, {ttl_hours} horas, {ttl_days} días)\")\n",
    "\n",
    "def test() -> None:\n",
    "    # Crear tablas\n",
    "    create_tables()\n",
    "    \n",
    "    # Generar datos de prueba\n",
    "    generate_sensor_data()\n",
    "    \n",
    "    # Ejecutar consultas de prueba\n",
    "    query_1('temperatura', 'SENS001')\n",
    "    query_2('humedad', 'SENS002')\n",
    "    query_3()\n",
    "    \n",
    "    # Limpiar tablas\n",
    "    drop_tables()\n",
    "\n",
    "test()\n",
    "# Cerrar conexión a Cassandra\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7617a",
   "metadata": {},
   "source": [
    "## P2. (13 pts) Evaluación Experimental\n",
    "\n",
    "### Cluster de Cassandra con Docker Compose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6045af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: '3.8'\n",
      "\n",
      "services:\n",
      "  cassandra1:\n",
      "    image: cassandra:4.1\n",
      "    container_name: cassandra1\n",
      "    hostname: cassandra1\n",
      "    networks:\n",
      "      - cassandra-net\n",
      "    ports:\n",
      "      - \"9042:9042\"\n",
      "    environment:\n",
      "      CASSANDRA_CLUSTER_NAME: \"CassandraCluster\"\n",
      "      CASSANDRA_DC: DC1\n",
      "      CASSANDRA_RACK: RAC1\n",
      "      CASSANDRA_SEEDS: \"cassandra1,cassandra2,cassandra3\"\n",
      "      MAX_HEAP_SIZE: 1024M\n",
      "      HEAP_NEWSIZE: 256M\n",
      "    mem_limit: 1536m\n",
      "\n",
      "  cassandra2:\n",
      "    image: cassandra:4.1\n",
      "    container_name: cassandra2\n",
      "    hostname: cassandra2\n",
      "    networks:\n",
      "      - cassandra-net\n",
      "    depends_on:\n",
      "      - cassandra1\n",
      "    environment:\n",
      "      CASSANDRA_CLUSTER_NAME: \"CassandraCluster\"\n",
      "      CASSANDRA_DC: DC1\n",
      "      CASSANDRA_RACK: RAC1\n",
      "      CASSANDRA_SEEDS: \"cassandra1,cassandra2,cassandra3\"\n",
      "      MAX_HEAP_SIZE: 1024M\n",
      "      HEAP_NEWSIZE: 256M\n",
      "    mem_limit: 1536m\n",
      "\n",
      "  cassandra3:\n",
      "    image: cassandra:4.1\n",
      "    container_name: cassandra3\n",
      "    hostname: cassandra3\n",
      "    networks:\n",
      "      - cassandra-net\n",
      "    depends_on:\n",
      "      - cassandra1\n",
      "    environment:\n",
      "      CASSANDRA_CLUSTER_NAME: \"CassandraCluster\"\n",
      "      CASSANDRA_DC: DC1\n",
      "      CASSANDRA_RACK: RAC1\n",
      "      CASSANDRA_SEEDS: \"cassandra1,cassandra2,cassandra3\"\n",
      "      MAX_HEAP_SIZE: 1024M\n",
      "      HEAP_NEWSIZE: 256M\n",
      "    mem_limit: 1536m\n",
      "\n",
      "networks:\n",
      "  cassandra-net:\n",
      "    driver: bridge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"docker-compose.yml\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "023c4461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Container cassandra2  Stopping\n",
      " Container cassandra3  Stopping\n",
      " Container cassandra3  Stopped\n",
      " Container cassandra3  Removing\n",
      " Container cassandra3  Removed\n",
      " Container cassandra2  Stopped\n",
      " Container cassandra2  Removing\n",
      " Container cassandra2  Removed\n",
      " Container cassandra1  Stopping\n",
      " Container cassandra1  Stopped\n",
      " Container cassandra1  Removing\n",
      " Container cassandra1  Removed\n",
      " Network lab15_cassandra-net  Removing\n",
      " Network lab15_cassandra-net  Removed\n",
      " Network lab15_cassandra-net  Creating\n",
      " Network lab15_cassandra-net  Created\n",
      " Container cassandra1  Creating\n",
      " Container cassandra1  Created\n",
      " Container cassandra3  Creating\n",
      " Container cassandra2  Creating\n",
      " Container cassandra3  Created\n",
      " Container cassandra2  Created\n",
      " Container cassandra1  Starting\n",
      " Container cassandra1  Started\n",
      " Container cassandra2  Starting\n",
      " Container cassandra3  Starting\n",
      " Container cassandra3  Started\n",
      " Container cassandra2  Started\n"
     ]
    }
   ],
   "source": [
    "!docker compose down -v\n",
    "!docker compose up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bbafc",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE KEYSPACE IF NOT EXISTS my_keyspace\n",
    "    WITH replication = {\n",
    "        'class': 'NetworkTopologyStrategy',\n",
    "        'datacenter1': '3'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace: my_keyspace\n",
      "Replicación: {'class': 'org.apache.cassandra.locator.NetworkTopologyStrategy', 'datacenter1': '3'}\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "session = cluster.connect()\n",
    "\n",
    "# Crear keyspace (si no existe)\n",
    "session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS my_keyspace\n",
    "    WITH replication = {\n",
    "        'class': 'NetworkTopologyStrategy',\n",
    "        'datacenter1': '3'\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "# Verificar la creación del keyspace\n",
    "rows = session.execute(\"\"\"\n",
    "    SELECT keyspace_name, replication\n",
    "    FROM system_schema.keyspaces\n",
    "    WHERE keyspace_name = 'my_keyspace'\n",
    "\"\"\")\n",
    "\n",
    "for row in rows:\n",
    "    print(\"Keyspace:\", row.keyspace_name)\n",
    "    print(\"Replicación:\", row.replication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "407a946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE           COMMAND                  CREATED          STATUS          PORTS                                                       NAMES\n",
      "5674d14e8152   cassandra:4.1   \"docker-entrypoint.s…\"   10 minutes ago   Up 10 minutes   7000-7001/tcp, 7199/tcp, 9042/tcp, 9160/tcp                 cassandra2\n",
      "3ba274a98a65   cassandra:4.1   \"docker-entrypoint.s…\"   10 minutes ago   Up 10 minutes   7000-7001/tcp, 7199/tcp, 9042/tcp, 9160/tcp                 cassandra3\n",
      "c62be9070c46   cassandra:4.1   \"docker-entrypoint.s…\"   10 minutes ago   Up 10 minutes   7000-7001/tcp, 7199/tcp, 9160/tcp, 0.0.0.0:9042->9042/tcp   cassandra1\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2076ebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load       Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  75.44 KiB  16      100.0%            91278d84-a6f5-4c4a-a15d-4d130f69f9c3  rack1\n",
      "UN  172.21.0.2  75.45 KiB  16      100.0%            911df817-5bbb-4120-8416-5a526e0645ae  rack1\n",
      "UN  172.21.0.3  75.44 KiB  16      100.0%            7d2e0357-0bdc-4cfe-be43-3236e4121186  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!docker exec cassandra1 nodetool status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d5b8b",
   "metadata": {},
   "source": [
    "### PostgreSQL\n",
    "Se usa una instancia local en el puerto 5432."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2498b7da",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.1\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.1\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\Jvnc\\Documents\\BD2\\BD2-Labs\\Lab15\\.conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - asyncpg\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    asyncpg-0.27.0             |  py311ha68e1ae_1         570 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         570 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  asyncpg            conda-forge/win-64::asyncpg-0.27.0-py311ha68e1ae_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "asyncpg-0.27.0       | 570 KB    |            |   0% \n",
      "asyncpg-0.27.0       | 570 KB    | 2          |   3% \n",
      "asyncpg-0.27.0       | 570 KB    | #6         |  17% \n",
      "asyncpg-0.27.0       | 570 KB    | ###6       |  36% \n",
      "asyncpg-0.27.0       | 570 KB    | #######8   |  79% \n",
      "asyncpg-0.27.0       | 570 KB    | ########## | 100% \n",
      "asyncpg-0.27.0       | 570 KB    | ########## | 100% \n",
      "asyncpg-0.27.0       | 570 KB    | ########## | 100% \n",
      "                                                     \n",
      " done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.3.1\n",
      "    latest version: 25.5.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge psycopg2\n",
    "%conda install -c conda-forge pandas\n",
    "%conda install -c conda-forge asyncpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c413f91",
   "metadata": {},
   "source": [
    "### Conexión desde Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4378aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement\n",
    "from datetime import datetime, timedelta\n",
    "from psycopg2.extras import execute_values\n",
    "from collections import defaultdict\n",
    "\n",
    "cluster = Cluster(\n",
    "  ['localhost'], port=9042,\n",
    "  protocol_version=4,\n",
    "  connect_timeout=5,\n",
    "  idle_heartbeat_interval=30,\n",
    "  control_connection_timeout=10\n",
    ")\n",
    "cassandra = cluster.connect('my_keyspace')\n",
    "\n",
    "connect = psycopg2.connect(dbname=\"lab15\",user=\"postgres\",password=\"postgres\",host=\"localhost\",port=5432)\n",
    "connect.autocommit = True\n",
    "postgres = connect.cursor()\n",
    "\n",
    "def create_table_cassandra() -> None:\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists temperature_measurements\n",
    "        (\n",
    "            sensor_id   text,\n",
    "            date        text,\n",
    "            event_time  timestamp,\n",
    "            temperature double,\n",
    "            humidity    double,\n",
    "            primary key ((sensor_id, date), event_time)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "def create_table_postgres() -> None:\n",
    "    postgres.execute(\"\"\"\n",
    "        create table if not exists temperature_measurements\n",
    "        (\n",
    "            sensor_id   varchar(20),\n",
    "            date        varchar(10),\n",
    "            event_time  timestamp,\n",
    "            temperature double precision,\n",
    "            humidity    double precision,\n",
    "            primary key (sensor_id, date, event_time)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "def create_tables() -> None:\n",
    "    create_table_cassandra()\n",
    "    create_table_postgres()\n",
    "\n",
    "def drop_table_cassandra() -> None:\n",
    "    cassandra.execute(\"drop table if exists temperature_measurements\")\n",
    "\n",
    "def drop_table_postgres() -> None:\n",
    "    postgres.execute(\"drop table if exists temperature_measurements\")\n",
    "\n",
    "def drop_tables() -> None:\n",
    "    drop_table_cassandra()\n",
    "    drop_table_postgres()\n",
    "\n",
    "NORMAL_RANGE = [(15, 35), (30, 80)]  # Rango normal para temperatura y humedad\n",
    "EXTENDED_RANGE = [(low - (high - low) * 0.2, high + (high - low) * 0.2) for low, high in NORMAL_RANGE]\n",
    "\n",
    "def generate_data(sensors: int, days: int) -> list[tuple]:\n",
    "    now = datetime.now()\n",
    "    ids = [f\"SENS{str(i).zfill(3)}\" for i in range(1, sensors + 1)]\n",
    "    data: list[tuple] = []\n",
    "    for id in ids:\n",
    "        for day in range(days):\n",
    "            date_obj = now - timedelta(days=day)\n",
    "            date_str = date_obj.strftime('%Y-%m-%d')\n",
    "            for minute in range(24 * 60):\n",
    "                timestamp = date_obj.replace(hour=0, minute=0, second=0, microsecond=0) + timedelta(minutes=minute)\n",
    "                temperature = random.uniform(*EXTENDED_RANGE[0])\n",
    "                humidity = random.uniform(*EXTENDED_RANGE[1])\n",
    "                data.append((id, date_str, timestamp, temperature, humidity))\n",
    "    return data\n",
    "\n",
    "def insert_postgres(data: list[tuple]) -> float:\n",
    "    drop_table_postgres()\n",
    "    create_table_postgres()\n",
    "    query = \"\"\"\n",
    "        INSERT INTO temperature_measurements (sensor_id, date, event_time, temperature, humidity)\n",
    "        VALUES %s\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    execute_values(postgres, query, data)\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "def insert_cassandra(data: list[tuple], batch_size: int) -> float:\n",
    "    drop_table_cassandra()\n",
    "    create_table_cassandra()\n",
    "    partitioned = defaultdict(list)\n",
    "    for row in data:\n",
    "        partitioned[(row[0], row[1])].append(row)\n",
    "    \n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        INSERT INTO temperature_measurements (sensor_id, date, event_time, temperature, humidity)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    \n",
    "    batch = BatchStatement()\n",
    "    start = time.time()\n",
    "    for rows in partitioned.values():\n",
    "        for i in range(0, len(rows), batch_size):\n",
    "            for row in rows[i:i + batch_size]:\n",
    "                batch.add(prepared, row)\n",
    "            cassandra.execute(batch)\n",
    "            batch.clear()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "def insert_test() -> None:\n",
    "    print(\"Prueba de inserción de datos:\")\n",
    "    volumes: list = [7, 15, 30, 60] # Volúmenes de datos en días\n",
    "    batch_sizes: list = [100, 200, 500, 1000]\n",
    "    columns = ['dias', 'postgres'] + [f'cassandra({size})' for size in batch_sizes]\n",
    "    results = pd.DataFrame(columns=columns)\n",
    "    for volume in volumes:\n",
    "        data: list[tuple] = generate_data(5, volume)\n",
    "        row = {'dias': volume}\n",
    "        row['postgres'] = insert_postgres(data)\n",
    "        for size in batch_sizes:\n",
    "            row[f'cassandra({size})'] = insert_cassandra(data, size)\n",
    "        results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f9abb",
   "metadata": {},
   "source": [
    "### a) Pruebas de Escritura (INSERT):\n",
    "Se realizaron pruebas preliminares de inserción individual en Cassandra utilizando un volumen reducido de 5 sensores durante 7 días. El tiempo requerido para completar la inserción fue excesivo, por lo que se descartó esta estrategia y se optó por evaluar únicamente la inserción por lotes (batch).\n",
    "\n",
    "Para los experimentos se emplearon los siguientes parámetros:\n",
    "- Sensores: 5\n",
    "- Volúmenes de datos en días: 7, 15, 30, 60\n",
    "\n",
    "En el caso de PostgreSQL, el tamaño del batch corresponde siempre al total de datos generados para cada volumen, es decir, toda la inserción se realiza en una sola operación masiva. Para Cassandra, se evaluaron diferentes tamaños de batch (100, 200, 500 y 1000) para analizar su impacto en el rendimiento.\n",
    "\n",
    "La tabla de resultados presenta una columna para PostgreSQL y una columna para cada tamaño de batch en Cassandra, agrupando los resultados por volumen de datos (días).\n",
    "\n",
    "Este enfoque permite comparar de manera clara el efecto del tamaño de batch en Cassandra y la diferencia de desempeño respecto a PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa273997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba de inserción de datos:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba de inserción de datos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dias</th>\n",
       "      <th>postgres</th>\n",
       "      <th>cassandra(100)</th>\n",
       "      <th>cassandra(200)</th>\n",
       "      <th>cassandra(500)</th>\n",
       "      <th>cassandra(1000)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2.109822</td>\n",
       "      <td>30.822227</td>\n",
       "      <td>15.861103</td>\n",
       "      <td>4.538761</td>\n",
       "      <td>4.344583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>3.271147</td>\n",
       "      <td>66.552932</td>\n",
       "      <td>34.268575</td>\n",
       "      <td>15.353234</td>\n",
       "      <td>8.453861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>143.133282</td>\n",
       "      <td>130.770741</td>\n",
       "      <td>5650.858164</td>\n",
       "      <td>30.523972</td>\n",
       "      <td>17.589561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>13.444289</td>\n",
       "      <td>999.740117</td>\n",
       "      <td>509.043554</td>\n",
       "      <td>61.017116</td>\n",
       "      <td>36.388920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dias    postgres  cassandra(100)  cassandra(200)  cassandra(500)   \n",
       "0    7    2.109822       30.822227       15.861103        4.538761  \\\n",
       "1   15    3.271147       66.552932       34.268575       15.353234   \n",
       "2   30  143.133282      130.770741     5650.858164       30.523972   \n",
       "3   60   13.444289      999.740117      509.043554       61.017116   \n",
       "\n",
       "   cassandra(1000)  \n",
       "0         4.344583  \n",
       "1         8.453861  \n",
       "2        17.589561  \n",
       "3        36.388920  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insert_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00914db6",
   "metadata": {},
   "source": [
    "#### Propuesta de Optimización: Inserción Asíncrona y Concurrente\n",
    "\n",
    "Para mejorar el rendimiento en la inserción masiva de datos, se propone el uso de estrategias asíncronas y concurrentes tanto en Cassandra como en PostgreSQL:\n",
    "\n",
    "- **Cassandra:** Utilizar `execute_async` para enviar múltiples lotes (batches) en paralelo, controlando la cantidad de operaciones simultáneas con un parámetro de workers. Esto permite aprovechar mejor los recursos del clúster y reducir el tiempo total de inserción.\n",
    "\n",
    "- **PostgreSQL:** Implementar inserción concurrente usando `ThreadPoolExecutor` junto con `execute_values` (psycopg2), donde cada thread maneja su propio batch y conexión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb26d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def insert_cassandra_async(data: list[tuple], batch_size: int, max_workers: int) -> float:\n",
    "    drop_table_cassandra()\n",
    "    create_table_cassandra()\n",
    "    partitioned = defaultdict(list)\n",
    "    for row in data:\n",
    "        partitioned[(row[0], row[1])].append(row)\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        INSERT INTO temperature_measurements (sensor_id, date, event_time, temperature, humidity)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "    \"\"\")\n",
    "    batches: list[BatchStatement] = []\n",
    "    for rows in partitioned.values():\n",
    "        for i in range(0, len(rows), batch_size):\n",
    "            batch = BatchStatement()\n",
    "            for row in rows[i:i + batch_size]:\n",
    "                batch.add(prepared, row)\n",
    "            batches.append(batch)\n",
    "    start = time.time()\n",
    "    futures = []\n",
    "    for batch in batches:\n",
    "        futures.append(cassandra.execute_async(batch))\n",
    "        if len(futures) >= max_workers:\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "            futures.clear()\n",
    "    for future in futures:\n",
    "        future.result()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "def insert_postgres_async(data: list[tuple], batch_size: int, max_workers: int) -> float:\n",
    "    drop_table_postgres()\n",
    "    create_table_postgres()\n",
    "    query = \"\"\"\n",
    "        insert into temperature_measurements (sensor_id, date, event_time, temperature, humidity)\n",
    "        values %s\n",
    "    \"\"\"\n",
    "    batches = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    start = time.time()\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(execute_values, postgres, query, batch) for batch in batches]\n",
    "        for future in as_completed(futures):\n",
    "            future.result()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "def insert_test_async() -> None:\n",
    "    print(\"Prueba de inserción de datos batch + async:\")\n",
    "    volumes: list[int] = [7, 15, 30, 60] # Volúmenes de datos en días\n",
    "    workers_amounts: list[int] = [2, 4, 8, 16]   # Cantidad de workers para la inserción asíncrona\n",
    "    columns = ['dias'] + [f'cassandra({workers})' for workers in workers_amounts] + [f'postgres({workers})' for workers in workers_amounts]\n",
    "    results = pd.DataFrame(columns=columns, dtype=float)\n",
    "    for volume in volumes:\n",
    "        data: list[tuple] = generate_data(5, volume)\n",
    "        row = {'dias': float(volume)}\n",
    "        for workers in workers_amounts:\n",
    "            row[f'cassandra({workers})'] = insert_cassandra_async(data, 1000, workers)\n",
    "            row[f'postgres({workers})'] = insert_postgres_async(data, 1000, workers)\n",
    "        results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54364a",
   "metadata": {},
   "source": [
    "Se realizaron pruebas variando la cantidad de workers para analizar cómo escala el rendimiento de inserción en ambos motores.\n",
    "\n",
    "Los resultados muestran que **Cassandra** aprovecha mucho mejor el aumento de concurrencia: a mayor número de workers y mayor volumen de datos, el tiempo de inserción disminuye significativamente, llegando incluso a superar el rendimiento de PostgreSQL en escenarios de alta concurrencia y grandes volúmenes.\n",
    "\n",
    "Por el contrario, **PostgreSQL** no presenta mejoras notables al incrementar la cantidad de workers bajo este enfoque, ya que su modelo de concurrencia y manejo de conexiones limita el beneficio de la paralelización en la inserción por lotes. Esto resalta la arquitectura distribuida y orientada a la escalabilidad de Cassandra frente al enfoque tradicional de PostgreSQL para cargas masivas de escritura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da1e3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba de inserción de datos batch + async:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dias</th>\n",
       "      <th>cassandra(2)</th>\n",
       "      <th>cassandra(4)</th>\n",
       "      <th>cassandra(8)</th>\n",
       "      <th>cassandra(16)</th>\n",
       "      <th>postgres(2)</th>\n",
       "      <th>postgres(4)</th>\n",
       "      <th>postgres(8)</th>\n",
       "      <th>postgres(16)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.350659</td>\n",
       "      <td>0.528152</td>\n",
       "      <td>0.374644</td>\n",
       "      <td>0.442715</td>\n",
       "      <td>1.152745</td>\n",
       "      <td>1.220498</td>\n",
       "      <td>1.146912</td>\n",
       "      <td>1.151179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.424133</td>\n",
       "      <td>0.980803</td>\n",
       "      <td>0.751128</td>\n",
       "      <td>0.654749</td>\n",
       "      <td>2.667092</td>\n",
       "      <td>2.705638</td>\n",
       "      <td>2.666091</td>\n",
       "      <td>2.746336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>6.270462</td>\n",
       "      <td>1.993381</td>\n",
       "      <td>1.564740</td>\n",
       "      <td>1.475055</td>\n",
       "      <td>5.539926</td>\n",
       "      <td>5.505820</td>\n",
       "      <td>5.416455</td>\n",
       "      <td>5.349141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>12.915060</td>\n",
       "      <td>3.903924</td>\n",
       "      <td>2.884975</td>\n",
       "      <td>2.543653</td>\n",
       "      <td>11.948052</td>\n",
       "      <td>11.177784</td>\n",
       "      <td>12.028290</td>\n",
       "      <td>13.132751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dias  cassandra(2)  cassandra(4)  cassandra(8)  cassandra(16)  postgres(2)   \n",
       "0   7.0      1.350659      0.528152      0.374644       0.442715     1.152745  \\\n",
       "1  15.0      3.424133      0.980803      0.751128       0.654749     2.667092   \n",
       "2  30.0      6.270462      1.993381      1.564740       1.475055     5.539926   \n",
       "3  60.0     12.915060      3.903924      2.884975       2.543653    11.948052   \n",
       "\n",
       "   postgres(4)  postgres(8)  postgres(16)  \n",
       "0     1.220498     1.146912      1.151179  \n",
       "1     2.705638     2.666091      2.746336  \n",
       "2     5.505820     5.416455      5.349141  \n",
       "3    11.177784    12.028290     13.132751  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insert_test_async()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc62cf",
   "metadata": {},
   "source": [
    "### b) Pruebas de Lectura (SELECT):\n",
    "1. Consulta por sensor y rango temporal: Obtener datos de un sensor específico en un día\n",
    "2. Consulta agregada: Calcular temperatura promedio de la última hora para múltiples sensores\n",
    "3. Consulta de rango de valores: Encontrar lecturas anómalas (fuera de rango normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a2388f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Lecturas del sensor SENS003 del día 2025-07-06:\n",
      "Cassandra (0.0912 segundos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-06 23:59:00</td>\n",
       "      <td>20.432070</td>\n",
       "      <td>50.138416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-06 23:58:00</td>\n",
       "      <td>36.385529</td>\n",
       "      <td>65.201529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-06 23:57:00</td>\n",
       "      <td>26.675042</td>\n",
       "      <td>73.799254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-06 23:56:00</td>\n",
       "      <td>20.527720</td>\n",
       "      <td>53.530202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-06 23:55:00</td>\n",
       "      <td>15.134275</td>\n",
       "      <td>20.709181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2025-07-06 00:04:00</td>\n",
       "      <td>32.254224</td>\n",
       "      <td>38.521825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2025-07-06 00:03:00</td>\n",
       "      <td>38.323663</td>\n",
       "      <td>72.440591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2025-07-06 00:02:00</td>\n",
       "      <td>38.082472</td>\n",
       "      <td>59.049028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2025-07-06 00:01:00</td>\n",
       "      <td>34.118799</td>\n",
       "      <td>77.032230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2025-07-06 00:00:00</td>\n",
       "      <td>28.108846</td>\n",
       "      <td>85.236772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_time  temperature   humidity\n",
       "0    2025-07-06 23:59:00    20.432070  50.138416\n",
       "1    2025-07-06 23:58:00    36.385529  65.201529\n",
       "2    2025-07-06 23:57:00    26.675042  73.799254\n",
       "3    2025-07-06 23:56:00    20.527720  53.530202\n",
       "4    2025-07-06 23:55:00    15.134275  20.709181\n",
       "...                  ...          ...        ...\n",
       "1435 2025-07-06 00:04:00    32.254224  38.521825\n",
       "1436 2025-07-06 00:03:00    38.323663  72.440591\n",
       "1437 2025-07-06 00:02:00    38.082472  59.049028\n",
       "1438 2025-07-06 00:01:00    34.118799  77.032230\n",
       "1439 2025-07-06 00:00:00    28.108846  85.236772\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL (0.0055 segundos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-06 23:59:00</td>\n",
       "      <td>20.432070</td>\n",
       "      <td>50.138416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-06 23:58:00</td>\n",
       "      <td>36.385529</td>\n",
       "      <td>65.201529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-06 23:57:00</td>\n",
       "      <td>26.675042</td>\n",
       "      <td>73.799254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-06 23:56:00</td>\n",
       "      <td>20.527720</td>\n",
       "      <td>53.530202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-06 23:55:00</td>\n",
       "      <td>15.134275</td>\n",
       "      <td>20.709181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2025-07-06 00:04:00</td>\n",
       "      <td>32.254224</td>\n",
       "      <td>38.521825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2025-07-06 00:03:00</td>\n",
       "      <td>38.323663</td>\n",
       "      <td>72.440591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2025-07-06 00:02:00</td>\n",
       "      <td>38.082472</td>\n",
       "      <td>59.049028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2025-07-06 00:01:00</td>\n",
       "      <td>34.118799</td>\n",
       "      <td>77.032230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2025-07-06 00:00:00</td>\n",
       "      <td>28.108846</td>\n",
       "      <td>85.236772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_time  temperature   humidity\n",
       "0    2025-07-06 23:59:00    20.432070  50.138416\n",
       "1    2025-07-06 23:58:00    36.385529  65.201529\n",
       "2    2025-07-06 23:57:00    26.675042  73.799254\n",
       "3    2025-07-06 23:56:00    20.527720  53.530202\n",
       "4    2025-07-06 23:55:00    15.134275  20.709181\n",
       "...                  ...          ...        ...\n",
       "1435 2025-07-06 00:04:00    32.254224  38.521825\n",
       "1436 2025-07-06 00:03:00    38.323663  72.440591\n",
       "1437 2025-07-06 00:02:00    38.082472  59.049028\n",
       "1438 2025-07-06 00:01:00    34.118799  77.032230\n",
       "1439 2025-07-06 00:00:00    28.108846  85.236772\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def query_1() -> None:\n",
    "    sensor_id = 'SENS003'\n",
    "    date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "    print(f\"Query 1: Lecturas del sensor {sensor_id} del día {date}:\")\n",
    "\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature, humidity\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        order by event_time desc\n",
    "    \"\"\")\n",
    "    start = time.time()\n",
    "    rows = cassandra.execute(prepared, (sensor_id, date))\n",
    "    end = time.time()\n",
    "    cassandra_time = end - start\n",
    "    print(f\"Cassandra ({cassandra_time:.4f} segundos):\")\n",
    "    display(pd.DataFrame(rows, columns=['event_time', 'temperature', 'humidity']))\n",
    "\n",
    "    start = time.time()\n",
    "    postgres.execute(\"\"\"\n",
    "        select event_time, temperature, humidity\n",
    "        from temperature_measurements\n",
    "        where sensor_id = %s\n",
    "        and date = %s\n",
    "        order by event_time desc\n",
    "    \"\"\", (sensor_id, date))\n",
    "    rows = postgres.fetchall()\n",
    "    end = time.time()\n",
    "    postgres_time = end - start\n",
    "    print(f\"PostgreSQL ({postgres_time:.4f} segundos):\")\n",
    "    display(pd.DataFrame(rows, columns=['event_time', 'temperature', 'humidity']))\n",
    "\n",
    "query_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae09a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 2: Temperatura promedio de la última hora para múltiples sensores:\n",
      "Cassandra (0.0929 segundos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENS001</td>\n",
       "      <td>25.702443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENS002</td>\n",
       "      <td>24.236884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENS003</td>\n",
       "      <td>23.855362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENS004</td>\n",
       "      <td>25.725693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENS005</td>\n",
       "      <td>26.446482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sensor_id   avg_temp\n",
       "0   SENS001  25.702443\n",
       "1   SENS002  24.236884\n",
       "2   SENS003  23.855362\n",
       "3   SENS004  25.725693\n",
       "4   SENS005  26.446482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL (0.0767 segundos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SENS001</td>\n",
       "      <td>25.702443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SENS002</td>\n",
       "      <td>24.236884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SENS003</td>\n",
       "      <td>23.855362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENS004</td>\n",
       "      <td>25.725693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SENS005</td>\n",
       "      <td>26.446482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sensor_id   avg_temp\n",
       "0   SENS001  25.702443\n",
       "1   SENS002  24.236884\n",
       "2   SENS003  23.855362\n",
       "3   SENS004  25.725693\n",
       "4   SENS005  26.446482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def query_2() -> None:\n",
    "    print(\"Query 2: Temperatura promedio de la última hora para múltiples sensores:\")\n",
    "    sensor_ids = [f'SENS{str(i).zfill(3)}' for i in range(1, 6)]\n",
    "    date = datetime.now().strftime('%Y-%m-%d')\n",
    "    hour = datetime.now() - timedelta(hours=1)\n",
    "\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        select temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        and event_time >= ?\n",
    "    \"\"\")\n",
    "    results: list[dict] = []\n",
    "    start = time.time()\n",
    "    for sensor_id in sensor_ids:\n",
    "        rows = list(cassandra.execute(prepared, (sensor_id, date, hour)))\n",
    "        avg_temp = sum(row.temperature for row in rows) / len(rows) if rows else None\n",
    "        row = {'sensor_id': sensor_id, 'avg_temp': avg_temp}\n",
    "        results.append(row)\n",
    "    end = time.time()\n",
    "    cassandra_time = end - start\n",
    "    print(f\"Cassandra ({cassandra_time:.4f} segundos):\")\n",
    "    display(pd.DataFrame(results))\n",
    "\n",
    "    query = \"\"\"\n",
    "        select sensor_id, avg(temperature) as avg_temp\n",
    "        from temperature_measurements\n",
    "        where date = %s\n",
    "        and event_time >= %s\n",
    "        group by sensor_id\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    postgres.execute(query, (date, hour))\n",
    "    rows = postgres.fetchall()\n",
    "    end = time.time()\n",
    "    postgres_time = end - start\n",
    "    print(f\"PostgreSQL ({postgres_time:.4f} segundos):\")\n",
    "    display(pd.DataFrame(rows, columns=['sensor_id', 'avg_temp']))\n",
    "\n",
    "query_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f11c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 3: Anomalías de temperatura del último día para el sensor SENS003:\n",
      "Cassandra (0.0852 segundos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-08 00:07:00</td>\n",
       "      <td>11.719097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-08 00:24:00</td>\n",
       "      <td>11.483746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-08 00:26:00</td>\n",
       "      <td>13.354506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-08 00:33:00</td>\n",
       "      <td>11.203284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-08 00:34:00</td>\n",
       "      <td>12.737963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2025-07-08 22:55:00</td>\n",
       "      <td>36.212633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>2025-07-08 23:22:00</td>\n",
       "      <td>38.680030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>2025-07-08 23:31:00</td>\n",
       "      <td>37.853090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>2025-07-08 23:47:00</td>\n",
       "      <td>36.550552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2025-07-08 23:50:00</td>\n",
       "      <td>37.191001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             event_time  temperature\n",
       "0   2025-07-08 00:07:00    11.719097\n",
       "1   2025-07-08 00:24:00    11.483746\n",
       "2   2025-07-08 00:26:00    13.354506\n",
       "3   2025-07-08 00:33:00    11.203284\n",
       "4   2025-07-08 00:34:00    12.737963\n",
       "..                  ...          ...\n",
       "424 2025-07-08 22:55:00    36.212633\n",
       "425 2025-07-08 23:22:00    38.680030\n",
       "426 2025-07-08 23:31:00    37.853090\n",
       "427 2025-07-08 23:47:00    36.550552\n",
       "428 2025-07-08 23:50:00    37.191001\n",
       "\n",
       "[429 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL (0.0030 segundos):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-08 00:00:00</td>\n",
       "      <td>36.981614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-08 00:05:00</td>\n",
       "      <td>38.235439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-08 00:07:00</td>\n",
       "      <td>11.719097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-08 00:08:00</td>\n",
       "      <td>37.144994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-08 00:14:00</td>\n",
       "      <td>36.326375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2025-07-08 23:24:00</td>\n",
       "      <td>12.891641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>2025-07-08 23:31:00</td>\n",
       "      <td>37.853090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>2025-07-08 23:47:00</td>\n",
       "      <td>36.550552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>2025-07-08 23:50:00</td>\n",
       "      <td>37.191001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2025-07-08 23:54:00</td>\n",
       "      <td>12.588746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             event_time  temperature\n",
       "0   2025-07-08 00:00:00    36.981614\n",
       "1   2025-07-08 00:05:00    38.235439\n",
       "2   2025-07-08 00:07:00    11.719097\n",
       "3   2025-07-08 00:08:00    37.144994\n",
       "4   2025-07-08 00:14:00    36.326375\n",
       "..                  ...          ...\n",
       "424 2025-07-08 23:24:00    12.891641\n",
       "425 2025-07-08 23:31:00    37.853090\n",
       "426 2025-07-08 23:47:00    36.550552\n",
       "427 2025-07-08 23:50:00    37.191001\n",
       "428 2025-07-08 23:54:00    12.588746\n",
       "\n",
       "[429 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def query_3() -> None:\n",
    "    print(\"Query 3: Anomalías de temperatura del último día para el sensor SENS003:\")\n",
    "    id = 'SENS003'\n",
    "    date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    low = NORMAL_RANGE[0][0]\n",
    "    high = NORMAL_RANGE[0][1]\n",
    "    prepared1 = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        and temperature < ?\n",
    "        allow filtering\n",
    "    \"\"\")\n",
    "    prepared2 = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        and temperature > ?\n",
    "        allow filtering\n",
    "    \"\"\")\n",
    "    start = time.time()\n",
    "    rows_low = cassandra.execute(prepared1, (id, date, low))\n",
    "    rows_high = cassandra.execute(prepared2, (id, date, high))\n",
    "    end = time.time()\n",
    "    cassandra_time = end - start\n",
    "    print(f\"Cassandra ({cassandra_time:.4f} segundos):\")\n",
    "    results: list = list(rows_low) + list(rows_high)\n",
    "    display(pd.DataFrame(results))\n",
    "\n",
    "    query = \"\"\"\n",
    "        select event_time, temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = %s\n",
    "        and date = %s\n",
    "        and (temperature < %s or temperature > %s)\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    postgres.execute(query, (id, date, low, high))\n",
    "    rows = postgres.fetchall()\n",
    "    end = time.time()\n",
    "    postgres_time = end - start\n",
    "    print(f\"PostgreSQL ({postgres_time:.4f} segundos):\")\n",
    "    display(pd.DataFrame(rows, columns=['event_time', 'temperature']))\n",
    "\n",
    "query_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7bc17",
   "metadata": {},
   "source": [
    "### c) Pruebas de Escalabilidad y Distribución:\n",
    "\n",
    "#### Evaluar el rendimiento con diferentes tamaños de dataset\n",
    "\n",
    "A continuación se presenta una código que genera un tabla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1967cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dias</th>\n",
       "      <th>query_1_postgres</th>\n",
       "      <th>query_1_cassandra</th>\n",
       "      <th>query_2_postgres</th>\n",
       "      <th>query_2_cassandra</th>\n",
       "      <th>query_3_postgres</th>\n",
       "      <th>query_3_cassandra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046451</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.080746</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.052265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.062288</td>\n",
       "      <td>0.012226</td>\n",
       "      <td>0.080369</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.038299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.032457</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.090534</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.037638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.121468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dias  query_1_postgres  query_1_cassandra  query_2_postgres   \n",
       "0   7.0          0.000000           0.046451          0.007188  \\\n",
       "1  15.0          0.004999           0.062288          0.012226   \n",
       "2  30.0          0.002019           0.032457          0.023674   \n",
       "3  60.0          0.003553           0.057512          0.096373   \n",
       "\n",
       "   query_2_cassandra  query_3_postgres  query_3_cassandra  \n",
       "0           0.080746          0.002201           0.052265  \n",
       "1           0.080369          0.002729           0.038299  \n",
       "2           0.090534          0.002949           0.037638  \n",
       "3           0.121468          0.000000           0.058627  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def query_1_test() -> tuple[float, float]:\n",
    "    sensor_id = 'SENS003'\n",
    "    date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature, humidity\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        order by event_time desc\n",
    "    \"\"\")\n",
    "    start = time.time()\n",
    "    rows = cassandra.execute(prepared, (sensor_id, date))\n",
    "    end = time.time()\n",
    "    cassandra_time = end - start\n",
    "    start = time.time()\n",
    "    postgres.execute(\"\"\"\n",
    "        select event_time, temperature, humidity\n",
    "        from temperature_measurements\n",
    "        where sensor_id = %s\n",
    "        and date = %s\n",
    "        order by event_time desc\n",
    "    \"\"\", (sensor_id, date))\n",
    "    rows = postgres.fetchall()\n",
    "    end = time.time()\n",
    "    postgres_time = end - start\n",
    "    return postgres_time, cassandra_time\n",
    "\n",
    "def query_2_test() -> tuple[float, float]:\n",
    "    date = datetime.now().strftime('%Y-%m-%d')\n",
    "    hour = datetime.now() - timedelta(hours=1)\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        select temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        and event_time >= ?\n",
    "    \"\"\")\n",
    "    sensor_ids = [f'SENS{str(i).zfill(3)}' for i in range(1, 6)]\n",
    "    results: list[dict] = []\n",
    "    start = time.time()\n",
    "    for sensor_id in sensor_ids:\n",
    "        rows = list(cassandra.execute(prepared, (sensor_id, date, hour)))\n",
    "        avg_temp = sum(row.temperature for row in rows) / len(rows) if rows else None\n",
    "        row = {'sensor_id': sensor_id, 'avg_temp': avg_temp}\n",
    "        results.append(row)\n",
    "    end = time.time()\n",
    "    cassandra_time = end - start\n",
    "    query = \"\"\"\n",
    "        select sensor_id, avg(temperature) as avg_temp\n",
    "        from temperature_measurements\n",
    "        where date = %s\n",
    "        and event_time >= %s\n",
    "        group by sensor_id\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    postgres.execute(query, (date, hour))\n",
    "    rows = postgres.fetchall()\n",
    "    end = time.time()\n",
    "    postgres_time = end - start\n",
    "    return postgres_time, cassandra_time\n",
    "\n",
    "def query_3_test() -> tuple[float, float]:\n",
    "    id = 'SENS003'\n",
    "    date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    low = NORMAL_RANGE[0][0]\n",
    "    high = NORMAL_RANGE[0][1]\n",
    "    prepared1 = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        and temperature < ?\n",
    "        allow filtering\n",
    "    \"\"\")\n",
    "    prepared2 = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        and temperature > ?\n",
    "        allow filtering\n",
    "    \"\"\")\n",
    "    start = time.time()\n",
    "    rows_low = cassandra.execute(prepared1, (id, date, low))\n",
    "    rows_high = cassandra.execute(prepared2, (id, date, high))\n",
    "    end = time.time()\n",
    "    cassandra_time = end - start\n",
    "    query = \"\"\"\n",
    "        select event_time, temperature\n",
    "        from temperature_measurements\n",
    "        where sensor_id = %s\n",
    "        and date = %s\n",
    "        and (temperature < %s or temperature > %s)\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    postgres.execute(query, (id, date, low, high))\n",
    "    rows = postgres.fetchall()\n",
    "    end = time.time()\n",
    "    postgres_time = end - start\n",
    "    return postgres_time, cassandra_time\n",
    "\n",
    "def test_queries() -> None:\n",
    "    volumes: list[int] = [7, 15, 30, 60]\n",
    "    columns = ['dias'] + [f'query_{i}_{db}' for i in range(1, 4) for db in ['postgres', 'cassandra']]\n",
    "    results = pd.DataFrame(columns=columns, dtype=float)\n",
    "    for volume in volumes:\n",
    "        row = {'dias': float(volume)}\n",
    "        drop_tables()\n",
    "        create_tables()\n",
    "        data: list[tuple] = generate_data(5, volume)\n",
    "        insert_cassandra_async(data, 1000, 16)\n",
    "        insert_postgres_async(data, 1000, 16)\n",
    "        queries = [query_1_test, query_2_test, query_3_test]\n",
    "        for i, query in enumerate(queries, start=1):\n",
    "            row[f'query_{i}_postgres'], row[f'query_{i}_cassandra'] = query()\n",
    "        results = pd.concat([results, pd.DataFrame([row])], ignore_index=True)\n",
    "    display(results)\n",
    "\n",
    "test_queries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303fcf31",
   "metadata": {},
   "source": [
    "#### Distribución de datos Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc74f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load       Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  10.46 MiB  16      100.0%            91278d84-a6f5-4c4a-a15d-4d130f69f9c3  rack1\n",
      "UN  172.21.0.2  10.48 MiB  16      100.0%            911df817-5bbb-4120-8416-5a526e0645ae  rack1\n",
      "UN  172.21.0.3  10.45 MiB  16      100.0%            7d2e0357-0bdc-4cfe-be43-3236e4121186  rack1\n",
      "\n",
      "Total number of tables: 45\n",
      "----------------\n",
      "Keyspace : my_keyspace\n",
      "\tRead Count: 0\n",
      "\tRead Latency: NaN ms\n",
      "\tWrite Count: 280\n",
      "\tWrite Latency: 4.262975 ms\n",
      "\tPending Flushes: 0\n",
      "\t\tTable: temperature_measurements\n",
      "\t\tSSTable count: 2\n",
      "\t\tOld SSTable count: 0\n",
      "\t\tSpace used (live): 10677017\n",
      "\t\tSpace used (total): 10677017\n",
      "\t\tSpace used by snapshots (total): 0\n",
      "\t\tOff heap memory used (total): 7508\n",
      "\t\tSSTable Compression Ratio: 0.7470015852751786\n",
      "\t\tNumber of partitions (estimate): 300\n",
      "\t\tMemtable cell count: 0\n",
      "\t\tMemtable data size: 0\n",
      "\t\tMemtable off heap memory used: 0\n",
      "\t\tMemtable switch count: 1\n",
      "\t\tSpeculative retries: 0\n",
      "\t\tLocal read count: 0\n",
      "\t\tLocal read latency: NaN ms\n",
      "\t\tLocal write count: 280\n",
      "\t\tLocal write latency: NaN ms\n",
      "\t\tPending flushes: 0\n",
      "\t\tPercent repaired: 0.0\n",
      "\t\tBytes repaired: 0.000KiB\n",
      "\t\tBytes unrepaired: 13.596MiB\n",
      "\t\tBytes pending repair: 0.000KiB\n",
      "\t\tBloom filter false positives: 0\n",
      "\t\tBloom filter false ratio: 0.00000\n",
      "\t\tBloom filter space used: 408\n",
      "\t\tBloom filter off heap memory used: 392\n",
      "\t\tIndex summary off heap memory used: 140\n",
      "\t\tCompression metadata off heap memory used: 6976\n",
      "\t\tCompacted partition minimum bytes: 42511\n",
      "\t\tCompacted partition maximum bytes: 51012\n",
      "\t\tCompacted partition mean bytes: 51012\n",
      "\t\tAverage live cells per slice (last five minutes): NaN\n",
      "\t\tMaximum live cells per slice (last five minutes): 0\n",
      "\t\tAverage tombstones per slice (last five minutes): NaN\n",
      "\t\tMaximum tombstones per slice (last five minutes): 0\n",
      "\t\tDropped Mutations: 0\n",
      "\t\tDroppable tombstone ratio: 0.00000\n",
      "\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "!docker exec cassandra1 nodetool status\n",
    "!docker exec cassandra1 nodetool cfstats my_keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e010e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load       Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  10.46 MiB  16      100.0%            91278d84-a6f5-4c4a-a15d-4d130f69f9c3  rack1\n",
      "UN  172.21.0.2  10.48 MiB  16      100.0%            911df817-5bbb-4120-8416-5a526e0645ae  rack1\n",
      "UN  172.21.0.3  10.45 MiB  16      100.0%            7d2e0357-0bdc-4cfe-be43-3236e4121186  rack1\n",
      "\n",
      "Total number of tables: 45\n",
      "----------------\n",
      "Keyspace : my_keyspace\n",
      "\tRead Count: 0\n",
      "\tRead Latency: NaN ms\n",
      "\tWrite Count: 283\n",
      "\tWrite Latency: 4.909388692579505 ms\n",
      "\tPending Flushes: 0\n",
      "\t\tTable: temperature_measurements\n",
      "\t\tSSTable count: 2\n",
      "\t\tOld SSTable count: 0\n",
      "\t\tSpace used (live): 10677102\n",
      "\t\tSpace used (total): 10677102\n",
      "\t\tSpace used by snapshots (total): 0\n",
      "\t\tOff heap memory used (total): 7508\n",
      "\t\tSSTable Compression Ratio: 0.7469277255384783\n",
      "\t\tNumber of partitions (estimate): 300\n",
      "\t\tMemtable cell count: 0\n",
      "\t\tMemtable data size: 0\n",
      "\t\tMemtable off heap memory used: 0\n",
      "\t\tMemtable switch count: 1\n",
      "\t\tSpeculative retries: 0\n",
      "\t\tLocal read count: 0\n",
      "\t\tLocal read latency: NaN ms\n",
      "\t\tLocal write count: 283\n",
      "\t\tLocal write latency: NaN ms\n",
      "\t\tPending flushes: 0\n",
      "\t\tPercent repaired: 0.0\n",
      "\t\tBytes repaired: 0.000KiB\n",
      "\t\tBytes unrepaired: 13.597MiB\n",
      "\t\tBytes pending repair: 0.000KiB\n",
      "\t\tBloom filter false positives: 0\n",
      "\t\tBloom filter false ratio: 0.00000\n",
      "\t\tBloom filter space used: 408\n",
      "\t\tBloom filter off heap memory used: 392\n",
      "\t\tIndex summary off heap memory used: 140\n",
      "\t\tCompression metadata off heap memory used: 6976\n",
      "\t\tCompacted partition minimum bytes: 14238\n",
      "\t\tCompacted partition maximum bytes: 51012\n",
      "\t\tCompacted partition mean bytes: 50848\n",
      "\t\tAverage live cells per slice (last five minutes): NaN\n",
      "\t\tMaximum live cells per slice (last five minutes): 0\n",
      "\t\tAverage tombstones per slice (last five minutes): NaN\n",
      "\t\tMaximum tombstones per slice (last five minutes): 0\n",
      "\t\tDropped Mutations: 0\n",
      "\t\tDroppable tombstone ratio: 0.00000\n",
      "\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "!docker exec cassandra2 nodetool status\n",
    "!docker exec cassandra2 nodetool cfstats my_keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3531c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load       Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.21.0.4  10.46 MiB  16      100.0%            91278d84-a6f5-4c4a-a15d-4d130f69f9c3  rack1\n",
      "UN  172.21.0.2  10.48 MiB  16      100.0%            911df817-5bbb-4120-8416-5a526e0645ae  rack1\n",
      "UN  172.21.0.3  10.45 MiB  16      100.0%            7d2e0357-0bdc-4cfe-be43-3236e4121186  rack1\n",
      "\n",
      "Total number of tables: 45\n",
      "----------------\n",
      "Keyspace : my_keyspace\n",
      "\tRead Count: 0\n",
      "\tRead Latency: NaN ms\n",
      "\tWrite Count: 280\n",
      "\tWrite Latency: 4.197903571428571 ms\n",
      "\tPending Flushes: 0\n",
      "\t\tTable: temperature_measurements\n",
      "\t\tSSTable count: 2\n",
      "\t\tOld SSTable count: 0\n",
      "\t\tSpace used (live): 10677017\n",
      "\t\tSpace used (total): 10677017\n",
      "\t\tSpace used by snapshots (total): 0\n",
      "\t\tOff heap memory used (total): 7508\n",
      "\t\tSSTable Compression Ratio: 0.7470015852751786\n",
      "\t\tNumber of partitions (estimate): 300\n",
      "\t\tMemtable cell count: 0\n",
      "\t\tMemtable data size: 0\n",
      "\t\tMemtable off heap memory used: 0\n",
      "\t\tMemtable switch count: 1\n",
      "\t\tSpeculative retries: 0\n",
      "\t\tLocal read count: 0\n",
      "\t\tLocal read latency: NaN ms\n",
      "\t\tLocal write count: 280\n",
      "\t\tLocal write latency: NaN ms\n",
      "\t\tPending flushes: 0\n",
      "\t\tPercent repaired: 0.0\n",
      "\t\tBytes repaired: 0.000KiB\n",
      "\t\tBytes unrepaired: 13.596MiB\n",
      "\t\tBytes pending repair: 0.000KiB\n",
      "\t\tBloom filter false positives: 0\n",
      "\t\tBloom filter false ratio: 0.00000\n",
      "\t\tBloom filter space used: 408\n",
      "\t\tBloom filter off heap memory used: 392\n",
      "\t\tIndex summary off heap memory used: 140\n",
      "\t\tCompression metadata off heap memory used: 6976\n",
      "\t\tCompacted partition minimum bytes: 42511\n",
      "\t\tCompacted partition maximum bytes: 51012\n",
      "\t\tCompacted partition mean bytes: 51012\n",
      "\t\tAverage live cells per slice (last five minutes): NaN\n",
      "\t\tMaximum live cells per slice (last five minutes): 0\n",
      "\t\tAverage tombstones per slice (last five minutes): NaN\n",
      "\t\tMaximum tombstones per slice (last five minutes): 0\n",
      "\t\tDropped Mutations: 0\n",
      "\t\tDroppable tombstone ratio: 0.00000\n",
      "\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "!docker exec cassandra3 nodetool status\n",
    "!docker exec cassandra3 nodetool cfstats my_keyspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88bfa8",
   "metadata": {},
   "source": [
    "#### Tolerancia a fallos en Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ad409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando tolerancia a fallos:\n",
      "\n",
      "Fallo en cassandra2:\n",
      "cassandra2\n",
      "Lecturas de SENS003 del día 2025-07-09 tras el fallo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-09 23:59:00</td>\n",
       "      <td>14.489894</td>\n",
       "      <td>88.452036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-09 23:58:00</td>\n",
       "      <td>27.333203</td>\n",
       "      <td>50.283353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-09 23:57:00</td>\n",
       "      <td>36.729118</td>\n",
       "      <td>61.678925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-09 23:56:00</td>\n",
       "      <td>32.053702</td>\n",
       "      <td>72.793595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-09 23:55:00</td>\n",
       "      <td>22.453724</td>\n",
       "      <td>22.655668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2025-07-09 00:04:00</td>\n",
       "      <td>29.528217</td>\n",
       "      <td>69.688122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2025-07-09 00:03:00</td>\n",
       "      <td>20.903408</td>\n",
       "      <td>44.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2025-07-09 00:02:00</td>\n",
       "      <td>28.781048</td>\n",
       "      <td>20.147594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2025-07-09 00:01:00</td>\n",
       "      <td>22.554355</td>\n",
       "      <td>84.396352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2025-07-09 00:00:00</td>\n",
       "      <td>35.016074</td>\n",
       "      <td>52.959126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_time  temperature   humidity\n",
       "0    2025-07-09 23:59:00    14.489894  88.452036\n",
       "1    2025-07-09 23:58:00    27.333203  50.283353\n",
       "2    2025-07-09 23:57:00    36.729118  61.678925\n",
       "3    2025-07-09 23:56:00    32.053702  72.793595\n",
       "4    2025-07-09 23:55:00    22.453724  22.655668\n",
       "...                  ...          ...        ...\n",
       "1435 2025-07-09 00:04:00    29.528217  69.688122\n",
       "1436 2025-07-09 00:03:00    20.903408  44.615700\n",
       "1437 2025-07-09 00:02:00    28.781048  20.147594\n",
       "1438 2025-07-09 00:01:00    22.554355  84.396352\n",
       "1439 2025-07-09 00:00:00    35.016074  52.959126\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recuperando cassandra1:\n",
      "cassandra2\n",
      "Lecturas de SENS003 del día 2025-07-09 tras la recuperación:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-09 23:59:00</td>\n",
       "      <td>14.489894</td>\n",
       "      <td>88.452036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-09 23:58:00</td>\n",
       "      <td>27.333203</td>\n",
       "      <td>50.283353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-09 23:57:00</td>\n",
       "      <td>36.729118</td>\n",
       "      <td>61.678925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-09 23:56:00</td>\n",
       "      <td>32.053702</td>\n",
       "      <td>72.793595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-09 23:55:00</td>\n",
       "      <td>22.453724</td>\n",
       "      <td>22.655668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2025-07-09 00:04:00</td>\n",
       "      <td>29.528217</td>\n",
       "      <td>69.688122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2025-07-09 00:03:00</td>\n",
       "      <td>20.903408</td>\n",
       "      <td>44.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2025-07-09 00:02:00</td>\n",
       "      <td>28.781048</td>\n",
       "      <td>20.147594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2025-07-09 00:01:00</td>\n",
       "      <td>22.554355</td>\n",
       "      <td>84.396352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2025-07-09 00:00:00</td>\n",
       "      <td>35.016074</td>\n",
       "      <td>52.959126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              event_time  temperature   humidity\n",
       "0    2025-07-09 23:59:00    14.489894  88.452036\n",
       "1    2025-07-09 23:58:00    27.333203  50.283353\n",
       "2    2025-07-09 23:57:00    36.729118  61.678925\n",
       "3    2025-07-09 23:56:00    32.053702  72.793595\n",
       "4    2025-07-09 23:55:00    22.453724  22.655668\n",
       "...                  ...          ...        ...\n",
       "1435 2025-07-09 00:04:00    29.528217  69.688122\n",
       "1436 2025-07-09 00:03:00    20.903408  44.615700\n",
       "1437 2025-07-09 00:02:00    28.781048  20.147594\n",
       "1438 2025-07-09 00:01:00    22.554355  84.396352\n",
       "1439 2025-07-09 00:00:00    35.016074  52.959126\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La recuperación fue exitosa: se mantuvieron los datos tras el fallo.\n"
     ]
    }
   ],
   "source": [
    "def test_failures() -> None:\n",
    "    print(\"Probando tolerancia a fallos:\")\n",
    "    # Simular fallo en cassandra1\n",
    "    print(\"\\nFallo en cassandra2:\")\n",
    "    !docker stop cassandra2\n",
    "    time.sleep(5)  # Esperar a que el nodo se considere caído\n",
    "\n",
    "    sensor_id = 'SENS003'\n",
    "    date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature, humidity\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        order by event_time desc\n",
    "    \"\"\")\n",
    "    rows_failure = cassandra.execute(prepared, (sensor_id, date))\n",
    "    print(f\"Lecturas de {sensor_id} del día {date} tras el fallo:\")\n",
    "    display(pd.DataFrame(rows_failure, columns=['event_time', 'temperature', 'humidity']))\n",
    "\n",
    "    # Simular recuperación de cassandra1\n",
    "    print(\"\\nRecuperando cassandra1:\")\n",
    "    !docker start cassandra2\n",
    "    time.sleep(10)  # Esperar a que el nodo se una al clúster\n",
    "\n",
    "    sensor_id = 'SENS003'\n",
    "    date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "    prepared = cassandra.prepare(\"\"\"\n",
    "        select event_time, temperature, humidity\n",
    "        from temperature_measurements\n",
    "        where sensor_id = ?\n",
    "        and date = ?\n",
    "        order by event_time desc\n",
    "    \"\"\")\n",
    "    rows_recovery = cassandra.execute(prepared, (sensor_id, date))\n",
    "    print(f\"Lecturas de {sensor_id} del día {date} tras la recuperación:\")\n",
    "    display(pd.DataFrame(rows_recovery, columns=['event_time', 'temperature', 'humidity']))\n",
    "\n",
    "    if len(list(rows_recovery)) == len(list(rows_failure)):\n",
    "        print(\"La recuperación fue exitosa: se mantuvieron los datos tras el fallo.\")\n",
    "    else:\n",
    "        print(\"La recuperación falló: los datos no se mantuvieron tras el fallo.\")\n",
    "\n",
    "test_failures()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
