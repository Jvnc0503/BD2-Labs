{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ecc817",
   "metadata": {},
   "source": [
    "# Lab15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248124a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Consultas requeridas\n",
    "1. Obtener todas las mediciones de humedad del sensor 'SENS001' del último día. La consulta debe incluir el tiempo restante de vida (TTL) de cada registro.\n",
    "\n",
    "2. Detectar valores anómalos fuera del rango permitido en la última hora. Implementar una consulta que identifique mediciones de temperatura o humedad fuera del rango normal. La consulta debe permitir filtrar por sensor específico.\n",
    "\n",
    "3. Verificar el tiempo restante de vida de los datos usando la función TTL. Implementar una consulta que muestre el TTL en diferentes unidades (segundos, horas, días). Crear una consulta para identificar datos que están próximos a expirar (ej: en las próximas 24 horas).\n",
    "\n",
    "## Estructura de tabla propuesta\n",
    "La tabla *sensor_readings* tendrá un propósito general que permite filtrar por tipo de medicion, sensor y día. Esta tabla se usará para la consulta 1.\n",
    "\n",
    "La tabla *sensor_anomalies* será destinada a optimizar la consulta 2, esta nos permite filtrar por hora ya que se incluye este dato en el partition key, además de tener clustering por el valor de la medición lo que facilita hallar los valores anómalos.\n",
    "\n",
    "La tabla *sensor_by_date* fue pensada para usarse con la consulta 3, porque particiona solo por la fecha y con esto poder filtrar los datos con más de 6 días de antigüedad.\n",
    "\n",
    "Se respeta el tiempo de vida de los datos de 7 días de acuerdo a lo solicitado, y se considera adicionalmente un tiempo de vida de solo 2 horas para el seguimiento de datos anómalos ya que se espera que siempre se consulten los insertados en la hora pasada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811eb3c",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "create table if not exists sensor_readings\n",
    "(\n",
    "    measurement_type text,\n",
    "    sensor_id        text,\n",
    "    date             text,\n",
    "    event_time       timestamp,\n",
    "    measurement      double,\n",
    "    primary key ( (measurement_type, sensor_id, date), event_time )\n",
    ") with clustering order by (event_time desc) and\n",
    "        default_time_to_live = 604800; -- 7 days\n",
    "\n",
    "create table if not exists sensor_anomalies\n",
    "(\n",
    "    measurement_type text,\n",
    "    sensor_id        text,\n",
    "    hour             text,\n",
    "    event_time       timestamp,\n",
    "    measurement      double,\n",
    "    primary key ( (measurement_type, sensor_id, hour), measurement, event_time)\n",
    ") with clustering order by (measurement asc, event_time desc) and\n",
    "        default_time_to_live = 7200; -- 2 hour\n",
    "\n",
    "create table if not exists sensor_by_date\n",
    "(\n",
    "    measurement_type text,\n",
    "    sensor_id        text,\n",
    "    date             text,\n",
    "    event_time       timestamp,\n",
    "    measurement      double,\n",
    "    primary key ( date, event_time )\n",
    ") with clustering order by (event_time desc) and\n",
    "        default_time_to_live = 604800; -- 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e96cc4",
   "metadata": {},
   "source": [
    "## Creación de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f58fbb15",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cassandra-driver in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (3.29.2)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.2.1)\n",
      "Requirement already satisfied: six in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jvnc\\documents\\bd2\\bd2-labs\\lab15\\.conda\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de prueba generados exitosamente.\n",
      "\n",
      "Query 1:\n",
      "Lecturas de temperatura para el sensor SENS001 del día de ayer 2025-07-07:\n",
      "12 resultados encontrados en 0.0163 segundos\n",
      "  - 2025-07-07 22:22:09: 27.575427960880024 (TTL: 604799 segundos)\n",
      "  - 2025-07-07 20:22:09: 34.7803031711525 (TTL: 604798 segundos)\n",
      "  - 2025-07-07 18:22:09: 34.472052054034165 (TTL: 604798 segundos)\n",
      "  - 2025-07-07 16:22:09: 22.855188008731396 (TTL: 604797 segundos)\n",
      "  - 2025-07-07 14:22:09: 15.096105327635264 (TTL: 604797 segundos)\n",
      "\n",
      "Query 2:\n",
      "Anomalías de humedad para el sensor SENS002 de la hora pasada 2025-07-08T01:\n",
      "0 resultados encontrados en 0.0280 segundos\n",
      "\n",
      "Query 3:\n",
      "Datos de más de 6 días de antigüedad (2025-07-02):\n",
      "12 resultados encontrados en 0.0159 segundos\n",
      "  - humedad del sensor SENS005 del día 2025-07-02 (TTL: 604771 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - humedad del sensor SENS005 del día 2025-07-02 (TTL: 604771 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - humedad del sensor SENS005 del día 2025-07-02 (TTL: 604770 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - humedad del sensor SENS005 del día 2025-07-02 (TTL: 604770 segundos, 10079 minutos, 167 horas, 6 días)\n",
      "  - humedad del sensor SENS005 del día 2025-07-02 (TTL: 604770 segundos, 10079 minutos, 167 horas, 6 días)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "# Parametros de simulación\n",
    "N_SENSORS = 5\n",
    "SAMPLING_RATE = 60 # 1 minuto en segundos\n",
    "SAMPLING_TIME = 604800  # 7 días en segundos\n",
    "ID_PREFIX = 'SENS'\n",
    "MESUREMENTS_TYPES = ('temperatura', 'humedad')\n",
    "NORMAL_RANGE = {'temperatura': (15, 35),\n",
    "                'humedad': (30, 80)}\n",
    "\n",
    "# Precomputar rango extendido de valores para simulación de anomalías\n",
    "EXTENDED_RANGE = {\n",
    "    type: (low - (high - low) * 0.2,\n",
    "        high + (high - low) * 0.2\n",
    "    )\n",
    "    for type, (low, high) in NORMAL_RANGE.items()\n",
    "}\n",
    "\n",
    "# Conexión a Cassandra en Docker\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "cassandra = cluster.connect('my_keyspace')\n",
    "\n",
    "def create_tables() -> None:\n",
    "    # Crear tabla para lecturas de sensores\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists sensor_readings\n",
    "        (\n",
    "            measurement_type text,\n",
    "            sensor_id        text,\n",
    "            date             text,\n",
    "            event_time       timestamp,\n",
    "            measurement      double,\n",
    "            primary key ( (measurement_type, sensor_id, date), event_time )\n",
    "        ) with clustering order by (event_time desc) and\n",
    "                default_time_to_live = 604800\n",
    "    \"\"\")\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists sensor_anomalies\n",
    "        (\n",
    "            measurement_type text,\n",
    "            sensor_id        text,\n",
    "            hour             text,\n",
    "            event_time       timestamp,\n",
    "            measurement      double,\n",
    "            primary key ( (measurement_type, sensor_id, hour), measurement, event_time)\n",
    "        ) with clustering order by (measurement asc, event_time desc) and\n",
    "                default_time_to_live = 7200\n",
    "    \"\"\")\n",
    "    cassandra.execute(\"\"\"\n",
    "        create table if not exists sensor_by_date\n",
    "        (\n",
    "            measurement_type text,\n",
    "            sensor_id        text,\n",
    "            date             text,\n",
    "            event_time       timestamp,\n",
    "            measurement      double,\n",
    "            primary key ( date, event_time )\n",
    "        ) with clustering order by (event_time desc) and\n",
    "                default_time_to_live = 604800\n",
    "    \"\"\")\n",
    "\n",
    "def drop_tables() -> None:\n",
    "    # Eliminar tablas si existen\n",
    "    cassandra.execute(\"drop table if exists sensor_readings\")\n",
    "    cassandra.execute(\"drop table if exists sensor_anomalies\")\n",
    "    cassandra.execute(\"drop table if exists sensor_by_date\")\n",
    "    \n",
    "def generate_sensor_data() -> None:\n",
    "    # Generar indetificadores únicos para cada sensor\n",
    "    sensor_id: list[str] = [f\"{ID_PREFIX}{str(i).zfill(3)}\" for i in range(1, N_SENSORS + 1)]\n",
    "\n",
    "    # Definir el tiempo de inicio y fin para la generación de datos\n",
    "    start_time: datetime = datetime.now() - timedelta(seconds=SAMPLING_TIME)\n",
    "    end_time: datetime = datetime.now()\n",
    "    current_time: datetime = start_time\n",
    "\n",
    "    while current_time <= end_time:\n",
    "        # Extraer fecha y hora del timestamp actual\n",
    "        date: str = current_time.strftime('%Y-%m-%d')\n",
    "        hour: str = current_time.strftime('%Y-%m-%dT%H')\n",
    "\n",
    "        for id in sensor_id:\n",
    "            for type in MESUREMENTS_TYPES:\n",
    "                ext_low, ext_high = EXTENDED_RANGE[type]\n",
    "                # Generar un valor en el rango extendido\n",
    "                measurement: float = random.uniform(ext_low, ext_high)\n",
    "                # Insertar en tablas\n",
    "                cassandra.execute(\"\"\"\n",
    "                    insert into sensor_readings(\n",
    "                        measurement_type, sensor_id, date, event_time, measurement\n",
    "                    ) values (%s, %s, %s, %s, %s)\n",
    "                \"\"\", (type, id, date, current_time, measurement))\n",
    "                cassandra.execute(\"\"\"\n",
    "                    insert into sensor_anomalies(\n",
    "                        measurement_type, sensor_id, hour, event_time, measurement\n",
    "                    ) values (%s, %s, %s, %s, %s)\n",
    "                \"\"\", (type, id, hour, current_time, measurement))\n",
    "                cassandra.execute(\"\"\"\n",
    "                    insert into sensor_by_date(\n",
    "                        measurement_type, sensor_id, date, event_time, measurement\n",
    "                    ) values (%s, %s, %s, %s, %s)\n",
    "                \"\"\", (type, id, date, current_time, measurement))\n",
    "        # Avanzar al siguiente intervalo de muestreo\n",
    "        current_time += timedelta(seconds=SAMPLING_RATE)\n",
    "    \n",
    "    print(\"Datos de prueba generados exitosamente.\")\n",
    "\n",
    "def query_1(type: str, id: str) -> None:\n",
    "    print(\"\\nQuery 1:\")\n",
    "    # Calcular el bucket del día anterior\n",
    "    target_date: str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    # Ejecutar consulta y medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "    rows = cassandra.execute(\"\"\"\n",
    "        select event_time, measurement, ttl(measurement) as ttl\n",
    "        from sensor_readings\n",
    "        where measurement_type = %s\n",
    "            and sensor_id = %s\n",
    "            and date = %s\n",
    "    \"\"\", (type, id, target_date))\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    rows: list = list(rows)  # Convertir a lista para poder usar len() y slicing\n",
    "    print(f\"Lecturas de {type} para el sensor {id} del día de ayer {target_date}:\")\n",
    "    print(f\"{len(rows)} resultados encontrados en {query_time:.4f} segundos\")\n",
    "    for row in rows[:5]:  # Limitar a las primeras 5 lecturas\n",
    "        event_time = row.event_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        measurement = row.measurement\n",
    "        ttl_seconds = row.ttl\n",
    "        print(f\"  - {event_time}: {measurement} (TTL: {ttl_seconds} segundos)\")\n",
    "\n",
    "def query_2(type: str, id: str) -> None:\n",
    "    print(\"\\nQuery 2:\")\n",
    "    # Calcular el bucket de la hora anterior\n",
    "    target_hour: str = (datetime.now() - timedelta(hours=1)).strftime('%Y-%m-%dT%H')\n",
    "    # Obtener el rango normal para el tipo de medición\n",
    "    low, high = NORMAL_RANGE[type]\n",
    "    # Ejecutar consulta y medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "    rows_low = cassandra.execute(\"\"\"\n",
    "        select event_time, measurement\n",
    "        from sensor_anomalies\n",
    "        where measurement_type = %s\n",
    "            and sensor_id = %s\n",
    "            and hour = %s\n",
    "            and measurement < %s\n",
    "    \"\"\", (type, id, target_hour, low))\n",
    "\n",
    "    rows_high = cassandra.execute(\"\"\"\n",
    "        select event_time, measurement\n",
    "        from sensor_anomalies\n",
    "        where measurement_type = %s\n",
    "            and sensor_id = %s\n",
    "            and hour = %s\n",
    "            and measurement > %s\n",
    "    \"\"\", (type, id, target_hour, high))\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    rows: list = list(rows_low) + list(rows_high)\n",
    "    rows.sort(key=lambda row: row.event_time, reverse=True)\n",
    "    print(f\"Anomalías de {type} para el sensor {id} de la hora pasada {target_hour}:\")\n",
    "    print(f\"{len(rows)} resultados encontrados en {query_time:.4f} segundos\")\n",
    "    for row in rows[:5]:  # Limitar a las primeras 5 anomalías\n",
    "        event_time = row.event_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        measurement = row.measurement\n",
    "        print(f\"  - {event_time}: {measurement}\")\n",
    "\n",
    "def query_3() -> None:\n",
    "    print(\"\\nQuery 3:\")\n",
    "    # Calcular el bucket de la fecha de hace 6 días\n",
    "    target_date: str = (datetime.now() - timedelta(days=6)).strftime('%Y-%m-%d')\n",
    "    # Ejecutar consulta y medir el tiempo de ejecución\n",
    "    start_time = time.time()\n",
    "    rows = cassandra.execute(\"\"\"\n",
    "        select measurement_type, sensor_id, date, event_time, ttl(measurement) as ttl\n",
    "        from sensor_by_date\n",
    "        where date = %s\n",
    "    \"\"\", (target_date,))\n",
    "    end_time = time.time()\n",
    "    query_time = end_time - start_time\n",
    "    rows: list = list(rows)  # Convertir a lista para poder usar len() y slicing\n",
    "    print(f\"Datos de más de 6 días de antigüedad ({target_date}):\")\n",
    "    print(f\"{len(rows)} resultados encontrados en {query_time:.4f} segundos\")\n",
    "    for row in rows[:5]:  # Limitar a las primeras 5 lecturas\n",
    "        measurement_type = row.measurement_type\n",
    "        sensor_id = row.sensor_id\n",
    "        date = row.date\n",
    "        ttl_seconds = row.ttl\n",
    "        ttl_minutes = ttl_seconds // 60\n",
    "        ttl_hours = ttl_minutes // 60\n",
    "        ttl_days = ttl_hours // 24\n",
    "        print(f\"  - {measurement_type} del sensor {sensor_id} del día {date} (TTL: {ttl_seconds} segundos, {ttl_minutes} minutos, {ttl_hours} horas, {ttl_days} días)\")\n",
    "\n",
    "def test() -> None:\n",
    "    # Crear tablas\n",
    "    create_tables()\n",
    "    \n",
    "    # Generar datos de prueba\n",
    "    generate_sensor_data()\n",
    "    \n",
    "    # Ejecutar consultas de prueba\n",
    "    query_1('temperatura', 'SENS001')\n",
    "    query_2('humedad', 'SENS002')\n",
    "    query_3()\n",
    "    \n",
    "    # Limpiar tablas\n",
    "    drop_tables()\n",
    "\n",
    "test()\n",
    "# Cerrar conexión a Cassandra\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
